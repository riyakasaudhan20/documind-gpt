# ğŸ¤– DocuMind - Backend (FastAPI)

This is the robust FastAPI backend for DocuMind. It orchestrates PDF parsing, vector embedding using ChromaDB, and intelligent retrieval-augmented generation (RAG) using LangChain.

---

## Features

- âœ… **Asynchronous PDF Processing**: Handles multiple uploads efficiently.
- ğŸ§  **Multi-Provider Support**: Seamlessly switch between Groq and Gemini.
- ğŸ” **Vector Transparency**: Inspect similarity search results and chunks.
- ğŸ›¡ï¸ **Pydantic Validation**: Strong typing for all API inputs and outputs.

---

## Project Structure

```
server/
â”œâ”€â”€ api/                        # FastAPI routes and schemas
â”œâ”€â”€ config/                     # Environment and constants
â”œâ”€â”€ core/                       # LLM logic, vectorstore, processing
â”œâ”€â”€ utils/                      # Logger and helpers
â”œâ”€â”€ main.py                     # App entry point
```

---

## ğŸ“¦ Installation

```bash
cd server
pip3 install -r requirements.txt
```

---

## Configuration

Set your API keys in a `.env` file in this directory:

- **Groq**: [console.groq.com](https://console.groq.com/)
- **Gemini**: [ai.google.dev](https://ai.google.dev)

```env
GROQ_API_KEY=your_groq_key
GOOGLE_API_KEY=your_google_key
```

---

## â–¶ï¸ Usage

Run the server:

```bash
uvicorn main:app --reload
```

---

## API Endpoints

- `POST /upload_and_process_pdfs`: Process documents for a provider.
- `POST /chat`: Start a RAG session.
- `GET /vector_store/count/{provider}`: Get indexed document count.
- `POST /vector_store/search`: Perform a test similarity search.
- `GET /llm`: List available providers.
- `GET /llm/{provider}`: List models for a provider.
- `GET /health`: System status check.

